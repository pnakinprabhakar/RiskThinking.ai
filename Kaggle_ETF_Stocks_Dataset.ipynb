{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5f3c769",
   "metadata": {},
   "source": [
    "# Problem 1: Raw Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3e8a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba92f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify your CSV file path\n",
    "symbol_file = 'C:\\Users\\Admin\\Desktop\\airflow\\symbols_valid_meta.csv'  \n",
    "\n",
    "# Read the CSV file\n",
    "df_symbols = pd.read_csv(symbol_file)\n",
    "\n",
    "#Subsetting the dataframe with ['Symbol','Security']\n",
    "df_symbols = df_symbols[['Symbol', 'Security Name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7f95213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Define the CSV files directories\n",
    "etf_dir = 'C:\\Users\\Admin\\Desktop\\airflow\\etfs'  \n",
    "stock_dir = 'C:\\Users\\Admin\\Desktop\\airflow\\stocks'  \n",
    "\n",
    "# Define a function to load and process the CSV files\n",
    "def process_files(dir_path):\n",
    "    dfs = []  # A list to store the dataframes\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            df = pd.read_csv(os.path.join(dir_path, file_name))\n",
    "            # Extract the required columns\n",
    "            df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
    "            dfs.append(df)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Process the ETF and stock data\n",
    "etf_data = process_files(etf_dir)\n",
    "stock_data = process_files(stock_dir)\n",
    "\n",
    "# Concatenate the ETF and stock data\n",
    "\n",
    "all_data = pd.concat([df_symbols,etf_data, stock_data], ignore_index=True)\n",
    "\n",
    "# Write the data to Parquet format\n",
    "all_data.to_parquet('all_data.parquet', engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d34015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Symbol                                      Security Name  \\\n",
      "0             A            Agilent Technologies, Inc. Common Stock   \n",
      "1            AA                    Alcoa Corporation Common Stock    \n",
      "2          AAAU                       Perth Mint Physical Gold ETF   \n",
      "3          AACG  ATA Creativity Global - American Depositary Sh...   \n",
      "4          AADR                AdvisorShares Dorsey Wright ADR ETF   \n",
      "...         ...                                                ...   \n",
      "28159802    NaN                                                NaN   \n",
      "28159803    NaN                                                NaN   \n",
      "28159804    NaN                                                NaN   \n",
      "28159805    NaN                                                NaN   \n",
      "28159806    NaN                                                NaN   \n",
      "\n",
      "                Date       Open       High        Low      Close  Adj Close  \\\n",
      "0                NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1                NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2                NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "3                NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4                NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "...              ...        ...        ...        ...        ...        ...   \n",
      "28159802  2020-03-26  23.379999  24.629999  23.379999  24.440001  24.440001   \n",
      "28159803  2020-03-27  24.000000  24.370001  23.629999  23.980000  23.980000   \n",
      "28159804  2020-03-30  24.200001  24.850000  23.910000  24.840000  24.840000   \n",
      "28159805  2020-03-31  24.730000  24.799999  24.030001  24.160000  24.160000   \n",
      "28159806  2020-04-01  23.760000  24.520000  23.730000  23.969999  23.969999   \n",
      "\n",
      "             Volume  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "...             ...  \n",
      "28159802  1294500.0  \n",
      "28159803   807100.0  \n",
      "28159804  1101600.0  \n",
      "28159805   685800.0  \n",
      "28159806  1750300.0  \n",
      "\n",
      "[28159807 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "459152e9",
   "metadata": {},
   "source": [
    "# Problem-2 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f77b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([etf_data, stock_data],ignore_index=True)\n",
    "# Calculate moving average of Volume\n",
    "data['vol_moving_avg'] = data['Volume'].rolling(window=30).mean()\n",
    "# Calculate rolling median of Adj Close\n",
    "data['adj_close_rolling_med'] = data['Adj Close'].rolling(window=30).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ed0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    NaN\n",
      "1                    NaN\n",
      "2                    NaN\n",
      "3                    NaN\n",
      "4                    NaN\n",
      "                ...     \n",
      "28151753    1.368950e+06\n",
      "28151754    1.381913e+06\n",
      "28151755    1.405967e+06\n",
      "28151756    1.420693e+06\n",
      "28151757    1.455340e+06\n",
      "Name: vol_moving_avg, Length: 28151758, dtype: float64\n",
      "0              NaN\n",
      "1              NaN\n",
      "2              NaN\n",
      "3              NaN\n",
      "4              NaN\n",
      "             ...  \n",
      "28151753    24.915\n",
      "28151754    24.435\n",
      "28151755    24.435\n",
      "28151756    24.295\n",
      "28151757    24.070\n",
      "Name: adj_close_rolling_med, Length: 28151758, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['vol_moving_avg'])\n",
    "print(data['adj_close_rolling_med'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68905a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date       Open       High        Low      Close  Adj Close  \\\n",
      "0         2013-06-18   4.807330   4.807330   4.807330   4.807330   4.486191   \n",
      "1         2013-06-19   4.991330   4.991330   4.991330   4.991330   4.657899   \n",
      "2         2013-06-20   4.916670   4.916670   4.916670   4.916670   4.588226   \n",
      "3         2013-06-21   5.020000   5.020000   5.020000   5.020000   4.684653   \n",
      "4         2013-06-24   5.136670   5.136670   5.136670   5.136670   4.793529   \n",
      "...              ...        ...        ...        ...        ...        ...   \n",
      "28151753  2020-03-26  23.379999  24.629999  23.379999  24.440001  24.440001   \n",
      "28151754  2020-03-27  24.000000  24.370001  23.629999  23.980000  23.980000   \n",
      "28151755  2020-03-30  24.200001  24.850000  23.910000  24.840000  24.840000   \n",
      "28151756  2020-03-31  24.730000  24.799999  24.030001  24.160000  24.160000   \n",
      "28151757  2020-04-01  23.760000  24.520000  23.730000  23.969999  23.969999   \n",
      "\n",
      "             Volume  vol_moving_avg  adj_close_rolling_med  \n",
      "0               0.0             NaN                    NaN  \n",
      "1               0.0             NaN                    NaN  \n",
      "2               0.0             NaN                    NaN  \n",
      "3               0.0             NaN                    NaN  \n",
      "4               0.0             NaN                    NaN  \n",
      "...             ...             ...                    ...  \n",
      "28151753  1294500.0    1.368950e+06                 24.915  \n",
      "28151754   807100.0    1.381913e+06                 24.435  \n",
      "28151755  1101600.0    1.405967e+06                 24.435  \n",
      "28151756   685800.0    1.420693e+06                 24.295  \n",
      "28151757  1750300.0    1.455340e+06                 24.070  \n",
      "\n",
      "[28151758 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be02893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('data.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = data[:int(data.shape[0]*0.8)]\n",
    "dataset_test = data[int(data.shape[0]*0.8):]\n",
    "\n",
    "#for c in data.columns[data.dtypes == 'object']:    \n",
    "#    dataset_train[c] = le.fit_transform(dataset_train[c])\n",
    "#    dataset_test[c] = le.transform(dataset_test[c])\n",
    "\n",
    "X_train, y_train = dataset_train.iloc[:,:-1],dataset_train.iloc[:,-1]\n",
    "X_test, y_test = dataset_test.iloc[:,:-1],dataset_test.iloc[:,-1]\n",
    "    \n",
    "#scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "print(dataset_train.shape,dataset_test.shape)\n",
    "#print(dataset_test)\n",
    "\n",
    "\n",
    "# Create a XGBRegressor model\n",
    "model = XGBRegressor()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#Save the resulting model to disk.\n",
    "np.savetxt('Results.csv',y_pred ,delimiter=',')\n",
    "\n",
    "\n",
    "# Calculate the variance\n",
    "print ('metrics.explained_variance_score : ', metrics.explained_variance_score(y_test, y_pred))\n",
    "\n",
    "# Calculate the mean_absolute_error\n",
    "print ('metrics.mean_absolute_error : ', metrics.mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# Calculate the metrics.mean_squared_error\n",
    "print ('metrics.mean_squared_error : ', metrics.r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
